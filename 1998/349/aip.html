<p><HTML>
<BODY BGCOLOR="#fffaff" TEXT="#000000" LINK="0000ff" VLINK="000080">
<div style="background:#ff6; padding:15px; border:1px solid #f00; text-align:center; font-weight:bold; width:95%;">
This page is a historical archive. For the latest information please visit <a href="http://www.commonsensereasoning.org/">commonsensereasoning.org</a>.
</div>

<table border=1 cellspacing=0 cellpadding=5>
<tr>
<td width="68%" bgcolor="#ccddee">
<h2>Javier Pinto</h2>
<h2>Causality in Theories of Action.</h2>
</td><td width="12%" align=right valign=top bgcolor="#d4ddbb">
<b>c-fcs-98-349<br>&#160;<br>
[<a href="/ext/etai/nj/fcs-98/349/paper.ps">original</a>]<br>
[<a href="/ext/etai/nj/fcs-98/349/abstract.html">abstract</a>]<br>


  </td><td width="20%" align=right valign=top bgcolor="#dddddd">
[<a href="mailto:javier@ing.puc.cl">mail to author</a>]<br>&#160;<br>

  [<a href="mailto: erisa@ida.liu.se">mail to moderator</a>]<br>
  [<a href="../debproc.html">debate
     procedure</a>]<br>
  [<a href="../copyright.html">copyright</a>]
  </tr></table>

<center>
<h1>Overview of interactions</h1>
</center>

<table width="100%" border=1 cellspacing=0 cellpadding=5>

<tr bgcolor="#e0e8e8">
<th width="4%" align=left>N:o</th>
<th width="38%" align=left>Question</th>
<th width="38%" align=left>Answer(s)</th>
<th width="20%" align=left>Continued discussion</th>
</tr>


<tr bgcolor="#d4ddbb">
<td width="4%" align=center valign=top bgcolor="dddddd">1 </td>

<td width="40%" valign=top>
    <a href="#003">7.1&#160;&#160;Graham White</a><br>
</td>
<td width="16%" valign=top>
    <a href="#004">29.1&#160;&#160;Javier Pinto</a><br>
</td>
<td width="40%" valign=top>
&#160;</td>
</tr>

<tr bgcolor="#d4ddbb">
<td width="4%" align=center valign=top bgcolor="dddddd">2 </td>

<td width="40%" valign=top>
    <a href="#001">7.1&#160;&#160;Erik Sandewall</a><br>
</td>
<td width="16%" valign=top>
    <a href="#002">29.1&#160;&#160;Javier Pinto</a><br>
</td>
<td width="40%" valign=top>
&#160;</td>
</tr>

<tr bgcolor="#d4ddbb">
<td width="4%" align=center valign=top bgcolor="dddddd">3 </td>

<td width="40%" valign=top>
    <a href="#005">7.1&#160;&#160;Tom Costello</a><br>
</td>
<td width="16%" valign=top>
    <a href="#006">29.1&#160;&#160;Javier Pinto</a><br>
</td>
<td width="40%" valign=top>
    <a href="#007">7.1&#160;&#160;Tom Costello</a><br>
    <a href="#008">29.1&#160;&#160;Javier Pinto</a><br>
</td>
</tr>
</table>
<p><font size=+1><a name="003">Q1. </a><b>Graham White</b>:</font><p>
<p>Assume that a child is able to deal with switches and lights. Do you
believe that the child has to have any knowledge of electrical current
for this to be possible?
<p><font size=+1><a name="004">A1. </a><b><a href="http://lyrcc.ing.puc.cl/jpinto/jpinto.html">Javier Pinto</a></b> (29.1):</font><p>
<p>  My work is not aimed towards dealing with children cognitive
  processes, therefore my answer is not based on any experimental
  evidence; rather, it is based on my own introspection and on my little
  experience with children development. I don't think that anybody could
  correctly analyze the behavior of the circuit without having some
  notion of what an electrical current is. Explanations based on other
  hypotheses might also be possible. The point of the paper is that if
  your explanations are based on explicit causal information, and if you
  do not get the right answers, you might want to change your model of
  the world to better reflect its behavior. Therefore, if a child gets
  the behavior wrong, because of a wrong analysis of the causal
  mechanism, the child should revise its knowledge, as opposed to revise
  his underlying reasoning mechanism to deal with causation. 
<p><hr>
<p><font size=+1><a name="001">Q2. </a><b><a href="http://www.ida.liu.se/~erisa/">Erik Sandewall</a></b>:</font><p>
<p>The representation examples that you have given are the classical ones,
which others have adequate solutions for as well. Are there some 
examples which your representation does correctly and which others can
not do right?
<p>
Also, the examples in the article are very simple ones. What is the most
complex example that you have done in this representation?
<p><font size=+1><a name="002">A2. </a><b><a href="http://lyrcc.ing.puc.cl/jpinto/jpinto.html">Javier Pinto</a></b> (29.1):</font><p>
<p>  The most complex examples are the standard examples that appear in the
  literature related to causality (along with some examples involving
  continuous change, common in the qualitative reasoning literature). I
  believe that the work of other people can also be seen as instances of
  what I propose (e.g. the work of Todd Kelley on qualitative physics).
  In particular, we have looked at extensions to the circuit example (as
  illustrated in the paper and taken from [thielscher97]. Also, as
  shown in the article, we use a similar approach to deal with
  indeterminacy. I admit that this latter treatment of indeterminacy
  might be regarded as too complex.  This added complexity is
  unavoidable, since we need to worry about the many possible outcomes
  of an indeterminate event, and must also be prepared to reason about
  each possible outcome. In future work I plan to study whether one can
  show a formal correspondence between approaches based on explicit
  causation and my own. My conjecture is that there is always a
  translation from an explicit causal representation and the one i
  propose. However, it remains to be seen if this translation is a
  natural one.
<p><hr>
<p><font size=+1><a name="005">Q3. </a><b><a href="http://www-formal.stanford.edu/tjc/home.html">Tom Costello</a></b>:</font><p>
<p>  People are able to verify systems as complex as the Pentium, why then
  worry about these silly little circuits?
<p><font size=+1><a name="006">A3. </a><b><a href="http://lyrcc.ing.puc.cl/jpinto/jpinto.html">Javier Pinto</a></b> (29.1):</font><p>
<p>  Well, I guess the best answer to this was given by John McCarthy,
  i.e., these sort of examples are the <em>drosophilas</em> of AI and
  Knowledge Representation. That is, the examples represent problems
  that are good testbeds for the different essential problems that we
  confront in AI. 
<p>
  Thus, these simple examples allow us to isolate a particular problem
  that we want to deal with. We do not need a zillion transistors to
  model the problems that arise when dealing with ramifications. In
  particular, this problem illustrates reasoning problems related to
  <em>causality</em>. There are many variants of this example, like the
  <em>stuffy room</em> example of Ginsberg and Smith [reasacti] and
  the suitcase with two latches of Lin <b><font color="#005588">[c-ijcai-95-1985]</font></b>.
  All these
  examples have allowed us to illustrate problems with our reasoning
  based on formalizations of these domains, and have helped us advance
  the state of the art in the area.
<p><b><em><font color="brown">References:</font></em></b><center><table width="96%">
<tr><td width="16%" valign="top"><font color="#005588"><b><a href="http://www.ida.liu.se/ext/acres/cf/ijcai/1995/indlis.html#1985">c-ijcai-95-1985</a></b></font></td><td width="84%"><a href="http://www.cs.toronto.edu/~cogrobo/">Fangzhen Lin</a>.<br>
Embracing Causality in Specifying the Indirect Effects of Actions. [<A HREF="http://www.cs.toronto.edu/~cogrobo/causality.ps.Z">postscript</A>] <br>
<font color="#005588">Proc. International Joint Conference on Artificial Intelligence, 1995, pp. 1985-1991.</font></td></tr>
</table></center>
<p><font size=+1><a name="007">C3-1. </a><b><a href="http://www-formal.stanford.edu/tjc/home.html">Tom Costello</a></b>:</font><p>
<p>What if the switches are very close, or if ...?
<p><font size=+1><a name="008">C3-2. </a><b><a href="http://lyrcc.ing.puc.cl/jpinto/jpinto.html">Javier Pinto</a></b> (29.1):</font><p>
<p>  The point of the question, as I understand it is that the model
  proposed did not account with the many different ways in which the
  model might be a mistaken idealization of reality. Certainly the model
  proposed is not geared towards dealing that particular issue. Rather,
  assuming that the circuit behaves the way it does, and that the
  primitive actions are independent flippings of the circuit, then how
  can we reason about it? Therefore, the answer is that we cannot deal
  with those situations since we were trying to deal with a completely
  separate set of issues.
<p><hr>
<p>This on-line debate page is part of a
<b><a href="../listing.html">discussion at recent workshop</a></b>;
similar pages are set up for each of the workshop articles.
The discussion is organized by the area
<a href="http://www.ida.liu.se/ext/etai/actions/">Reasoning about
Actions and Change</a> within the
<b>Electronic Transactions on Artificial Intelligence</b>
(<a href="http://www.ida.liu.se/ext/etai/">ETAI</a>).
<p>

To contribute, please click [mail to moderator] above and send your 
question or comment as an E-mail message.
<p>
<hr>
<p>
</body> </html>
